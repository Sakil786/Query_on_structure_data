{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xoesIsB8uPdU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import duckdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langgraph langchain-community pypdf faiss-cpu sentence-transformers langchain-groq"
      ],
      "metadata": {
        "id": "Jq7_6XmcuXH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAbXX8vUvBOU",
        "outputId": "61ef0636-c39f-4842-fae9-a5ea4d304614"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the path to the transactional data\n",
        "TRANSACTION_DATA_FILE_PATH = '/content/Titanic-Dataset.csv'"
      ],
      "metadata": {
        "id": "NpeqjcVRyS9j"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the path to the transactional data\n",
        "TRANSACTION_DATA_FILE_PATH = '/content/Titanic-Dataset.csv'"
      ],
      "metadata": {
        "id": "La6LPSoTvxrO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq()"
      ],
      "metadata": {
        "id": "Cut2qm-_wl2f"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=\"deepseek-r1-distill-llama-70b\""
      ],
      "metadata": {
        "id": "wYVmRTJEwqVp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import duckdb\n",
        "from groq import Groq\n",
        "# from helper import get_groq_api_key  # Ensure this function fetches the Groq API key\n",
        "\n",
        "# Initialize the Groq client\n",
        "groq_api_key = \"gsk_TGJDpgzTUYmkCsEMcJeXWGdyi\"\n",
        "client = Groq(api_key=groq_api_key)\n",
        "\n",
        "# Define the model name\n",
        "MODEL = \"gemma2-9b-it\"\n",
        "\n",
        "# Define the path to the Titanic dataset\n",
        "TRANSACTION_DATA_FILE_PATH = \"/content/Titanic-Dataset.csv\"\n",
        "\n",
        "# SQL generation prompt template\n",
        "SQL_GENERATION_PROMPT = \"\"\"\n",
        "Generate an SQL query based on a prompt. Do not reply with anything besides the SQL query.\n",
        "The prompt is: {prompt}\n",
        "\n",
        "The available columns are: {columns}\n",
        "The table name is: {table_name}\n",
        "\"\"\"\n",
        "\n",
        "# Function to generate SQL query using Groq's streaming format\n",
        "def generate_sql_query(prompt: str, columns: list, table_name: str) -> str:\n",
        "    \"\"\"Generate an SQL query using Groq's streaming LLM\"\"\"\n",
        "    formatted_prompt = SQL_GENERATION_PROMPT.format(\n",
        "        prompt=prompt, columns=columns, table_name=table_name\n",
        "    )\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
        "        temperature=0.6,\n",
        "        max_completion_tokens=512,\n",
        "        top_p=0.95,\n",
        "        stream=True,  # Enable streaming\n",
        "    )\n",
        "\n",
        "    sql_query = \"\"\n",
        "    for chunk in response:\n",
        "        sql_query += chunk.choices[0].delta.content or \"\"  # Extract the response incrementally\n",
        "\n",
        "    # Clean the SQL response\n",
        "    return sql_query.strip().replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
        "\n",
        "# Function to query Titanic data using SQL and DuckDB\n",
        "def lookup_data(prompt: str) -> str:\n",
        "    \"\"\"Query Titanic dataset using SQL generated by Groq\"\"\"\n",
        "    try:\n",
        "        table_name = \"titanic1\"\n",
        "\n",
        "        # Load the dataset\n",
        "        df = pd.read_csv(TRANSACTION_DATA_FILE_PATH)\n",
        "\n",
        "        # Create a DuckDB in-memory connection\n",
        "        con = duckdb.connect()\n",
        "\n",
        "        # Register the DataFrame as a table (correct way)\n",
        "        con.register(table_name, df)\n",
        "\n",
        "        # Generate SQL query\n",
        "        sql_query = generate_sql_query(prompt, df.columns.tolist(), table_name)\n",
        "\n",
        "        # Execute SQL query\n",
        "        result = con.execute(sql_query).fetchdf()\n",
        "\n",
        "        return result.to_string()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error accessing data: {str(e)}\"\n",
        "\n",
        "# Example usage\n",
        "example_data = lookup_data(\"List out the column names in Titanic data\")\n",
        "print(example_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TILJeiDK3J6M",
        "outputId": "c69730f4-733e-4ac1-ea7e-b452c58e5f96"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    column_name\n",
            "0   PassengerId\n",
            "1      Survived\n",
            "2        Pclass\n",
            "3          Name\n",
            "4           Sex\n",
            "5           Age\n",
            "6         SibSp\n",
            "7         Parch\n",
            "8        Ticket\n",
            "9          Fare\n",
            "10        Cabin\n",
            "11     Embarked\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data = lookup_data(\"How many male and female are  in the titanic dataset?\")\n",
        "print(example_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j5zxLjd79M_",
        "outputId": "120c3566-819d-4a31-9d88-43b621467dcc"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   male_count  female_count\n",
            "0         577           314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data = lookup_data(\"Find the missing values count  in the titanic dataset?\")\n",
        "print(example_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6BFfvKh9D2g",
        "outputId": "355495d1-224b-45f7-f6d6-3ae02112c949"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Missing_Age  Missing_Cabin\n",
            "0          177            687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data = lookup_data(\"Give the summary about the dataset and find the insights from the dataset\")\n",
        "print(example_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-HhynJE8ZIp",
        "outputId": "747cdb49-92b5-47b5-82ee-2d764df315e8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   average_survival_rate  total_passengers  number_survivors  number_deceased  total_fare  max_age  min_age  number_of_passenger_classes\n",
            "0               0.383838               891               342              549  28693.9493     80.0     0.42                            3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hayXBoCq-Yj_"
      },
      "execution_count": 61,
      "outputs": []
    }
  ]
}